---
title: "101C Final"
author: "Park"
date: "11/24/2019"
output: pdf_document
---

```{r}
library(dplyr)
train.full = read.csv("train.csv")
test.full = read.csv("test.csv")
test.full = test.full %>% mutate(HTWins = NA)

#Row bind train and test dataset
#Drop ID and game ID which we don't need
mix <- rbind(train.full, test.full)
mix <- mix %>% subset(select = -c(id, gameID)) 
#%>%  
#  mutate(date = as.Date(as.character(date), "%Y%m%d"),
#         train.test = ifelse(is.na(HTWins), "test", "train"))


#Check the timeline of train and test data
mix %>% filter(!is.na(HTWins)) %>%
  select(date) %>% tail(10)
mix %>% filter(is.na(HTWins)) %>%
  select(date) %>% head(10)
```

```{r}
#Delete all the variable which are not informaiton of hometeam that has correlation of 1
mix <- mix %>% select(subset = -c(VT.TS.fgm, VT.TS.fga, VT.TS.tpm, VT.TS.tpa, VT.TS.fta, VT.TS.oreb, VT.TS.dreb, VT.TS.ast,
                                  VT.TS.stl,VT.TS.blk,VT.TS.to,VT.TS.pf,VT.TS.pts, VT.TA.fga, VT.TA.tpm,VT.TA.tpa,VT.TA.fta, 
                                  VT.TA.oreb, VT.TA.dreb, VT.TA.ast, VT.TA.stl,VT.TA.to, VT.TA.pf, VT.TA.pts,VT.OTS.fgm, 
                                  VT.OTS.fga, VT.OTS.tpm, VT.OTS.tpa, VT.OTS.fta, VT.OTS.oreb, VT.OTS.dreb, VT.OTS.stl, 
                                  VT.OTS.blk, VT.OTS.pf, VT.OTS.pts,VT.OTA.fgm, VT.OTA.fga, VT.OTA.tpa, VT.OTA.fta,
                                  VT.OTA.fta, VT.OTA.blk, VT.OTA.to, VT.OTA.pts, VT.S1.plmin , VT.S3.plmin, VT.S4.plmin, VT.S5.plmin,
                                  VT.OS1.plmin, VT.OS2.plmin, VT.OS3.plmin, VT.OTS.fgm, VT.OTS.fga, VT.OTS.tpm, VT.OTS.tpa,
                                  VT.OTS.fta, VT.OTS.oreb, VT.OTS.dreb, VT.OTS.stl, VT.OTS.blk, VT.OTS.pf, VT.OTS.pts, VT.OTA.fgm,
                                  VT.OTA.fga, VT.OTA.tpa, VT.OTA.fta, VT.OTA.ast, VT.OTA.blk, VT.OTA.to, VT.OTA.pts, VT.TS.fgm,
                                  VT.TS.fga, VT.TS.tpm, VT.TS.tpa, VT.TS.fta, VT.TS.oreb, VT.TS.dreb, VT.TS.ast, VT.TS.stl,
                                  VT.TS.blk, VT.TS.to, VT.TS.pf, VT.TS.pts, VT.TA.fga, VT.TA.tpm, VT.TA.tpa, VT.TA.fta, VT.TA.oreb,
                                  VT.TA.dreb, VT.TA.ast, VT.TA.stl, VT.TA.to, VT.TA.pf, VT.TA.pts, VT.OS1.plmin, VT.OS2.plmin,
                                  VT.OS3.plmin, VT.S1.plmin, VT.S3.plmin, VT.S4.plmin, VT.S5.plmin))

#Extract column names of the numeric variables
num.var1 <- mix %>% select_if(is.numeric) %>% colnames
num.var1



#"HT.TS.fgm"    "HT.TS.fga"    "HT.TS.tpm"    "HT.TS.tpa"    "HT.TS.fta"    "HT.TS.oreb"   "HT.TS.dreb"   "HT.TS.ast"    "HT.TS.stl"   
#"HT.TS.blk"    "HT.TS.to"     "HT.TS.pf"     "HT.TS.pts"

#"HT.TA.fgm"    "HT.TA.fga"    "HT.TA.tpm"    "HT.TA.tpa"    "HT.TA.fta"    "HT.TA.oreb"   "HT.TA.dreb"  
#"HT.TA.ast"    "HT.TA.stl"    "HT.TA.blk"    "HT.TA.to"     "HT.TA.pf"     "HT.TA.pts"

#"HT.OTS.fgm"   "HT.OTS.fga"   "HT.OTS.tpm"   "HT.OTS.tpa"   "HT.OTS.fta"  
#"HT.OTS.oreb"  "HT.OTS.dreb"  "HT.OTS.ast"   "HT.OTS.stl"   "HT.OTS.blk"   "HT.OTS.to"    "HT.OTS.pf"    "HT.OTS.pts"   

#"HT.OTA.fgm"   "HT.OTA.fga"   "HT.OTA.tpm"  "HT.OTA.tpa"   "HT.OTA.fta"   "HT.OTA.oreb"  "HT.OTA.dreb"  "HT.OTA.ast"   "HT.OTA.stl"   "HT.OTA.blk"   "HT.OTA.to"    "HT.OTA.pf"    #"HT.OTA.pts"

#"HT.S1.plmin"  "HT.S1.pts"    "HT.S1.min"    "HT.S1.stl"    "HT.S1.ast"    
#"HT.S2.plmin"  "HT.S2.pts"    "HT.S2.min"    "HT.S2.stl"    "HT.S2.ast"    
#"HT.S3.plmin"  "HT.S3.pts"    "HT.S3.min"    "HT.S3.stl"    "HT.S3.ast"    
#"HT.S4.plmin"  "HT.S4.pts"    "HT.S4.min"    "HT.S4.stl"    "HT.S4.ast"    
#"HT.S5.plmin"  "HT.S5.pts"    "HT.S5.min"    "HT.S5.stl"    "HT.S5.ast"

#"HT.OS1.plmin" "HT.OS1.dreb"  "HT.OS1.to"    "HT.OS1.fgm"   "HT.OS1.oreb"  
#"HT.OS2.plmin" "HT.OS2.dreb"  "HT.OS2.to"    "HT.OS2.fgm"   "HT.OS2.oreb"  
#"HT.OS3.plmin" "HT.OS3.dreb"  "HT.OS3.to"    "HT.OS3.fgm"   "HT.OS3.oreb"  
#"HT.OS4.plmin" "HT.OS4.dreb"  "HT.OS4.to"    "HT.OS4.fgm"   "HT.OS4.oreb" 
#"HT.OS5.plmin" "HT.OS5.dreb"  "HT.OS5.to"    "HT.OS5.fgm"   "HT.OS5.oreb"  

#"VT.S1.pts"    "VT.S1.min"    "VT.S1.stl"    "VT.S1.ast"    
#"VT.S2.plmin"  "VT.S2.pts"    "VT.S2.min"    "VT.S2.stl"    "VT.S2.ast"    
#"VT.S3.pts"    "VT.S3.min"    "VT.S3.stl"    "VT.S3.ast"    
#"VT.S4.pts"    "VT.S4.min"    "VT.S4.stl"    "VT.S4.ast"    
#"VT.S5.pts"    "VT.S5.min"    "VT.S5.stl"    "VT.S5.ast"   

#"VT.OS1.dreb"  "VT.OS1.to"    "VT.OS1.fgm"   "VT.OS1.oreb"  
#"VT.OS2.dreb"  "VT.OS2.to"    "VT.OS2.fgm"   "VT.OS2.oreb"  
#"VT.OS3.dreb"  "VT.OS3.to"    "VT.OS3.fgm"   "VT.OS3.oreb"  
#"VT.OS4.plmin" "VT.OS4.dreb"  "VT.OS4.to"    "VT.OS4.fgm"   "VT.OS4.oreb"  
#"VT.OS5.plmin" "VT.OS5.dreb"  "VT.OS5.to"    "VT.OS5.fgm"   "VT.OS5.oreb"

#"HT.pmxU"      "HT.pmxW"     

```


```{r}
##See the overall pattern of data
library(ggplot2)
#Home team field goal made / attempted
#Kind of sig
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.fgm/HT.TS.fga)) + geom_boxplot()

#Home team, opposing team field goal made / attempted
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.OTS.fgm/HT.OTS.fga)) + geom_boxplot()

#Home team three point goal made / attempted
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.tpm/HT.TS.tpa)) + geom_boxplot()

#Home team, opposing team three point goal made/attempted
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.OTS.tpm/HT.OTS.tpa)) + geom_boxplot()

#Home team scored offensive rebound / defensive rebound
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.oreb/HT.TS.dreb)) + geom_boxplot()

#Home team free throws scored / allowed
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.fta/HT.TA.fta)) + geom_boxplot()

#Home team rest / total rest
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HTcumRest/(VTcumRest + HTcumRest))) + geom_boxplot()

#Home team scored personal foul / total foul
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.pf/(HT.TA.pf +HT.TS.pf))) + geom_boxplot()

#Home team scored block / total block
mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.blk/(HT.TS.blk +HT.TA.blk))) + geom_boxplot()

mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.TS.fgm/HT.OTS.fgm)) + geom_boxplot()

mix %>% filter(!is.na(HTWins)) %>% ggplot(aes(x = HTWins, y = HT.Team.plmin.zscore)) + geom_boxplot()
```


```{r}
#HT.S.plmin by team
mix %>% filter(!is.na(HTWins)) %>% select(HTWins, contains("plm")) %>%
  group_by(HTWins) %>% summarise(mean = mean(HT.S1.plmin))

#function for applying function
express.func <- function(pattern, func){
  return(
    apply(mix[,grepl(pattern, colnames(mix))], 1, func)
  )
}

#Sum of S.plmin
mix <- mix %>% 
  mutate(VT.S.plmin.sum = express.func("^VT.S[0-9].plmin*",sum),
         HT.S.plmin.sum = express.func("^HT.S[0-9].plmin*",sum))

mix %>% filter(!is.na(HTWins)) %>% 
  group_by(HTWins) %>% summarise(mean.VT.S.sum = mean(VT.S.plmin.sum),
                                 mean.HT.S.sum = mean(HT.S.plmin.sum))

#HT.S.plmin by each team
HT.S.plmin <- mix %>% filter(!is.na(HTWins)) %>%
  group_by(HT) %>% summarise(mean.HT.S.plmin.sum = mean(HT.S.plmin.sum),
                             sd.HT.S.plmin.sum = sd(HT.S.plmin.sum))

#Zscore for HT.S.plmin
mix <- mix %>% left_join(HT.S.plmin, by="HT") %>% 
  mutate(HT.Team.plmin.zscore = (HT.S.plmin.sum-mean.HT.S.plmin.sum)/sd.HT.S.plmin.sum) %>%
  select(subset = -c(mean.HT.S.plmin.sum, sd.HT.S.plmin.sum))

#Sum of S.pts
mix <- mix %>% 
  mutate(VT.S.pts.sum = express.func("^VT.S[0-9].pts*",sum),
         HT.S.pts.sum = express.func("^HT.S[0-9].pts*",sum))
```

```{r}
#Tree base model for prediction
library(randomForest)
train = mix %>% filter(!is.na(HTWins))
test = mix %>% filter(is.na(HTWins))
model1 <- randomForest(HTWins ~ ., data = train, ntree = 500, mtry = 6, importance = TRUE)
model1
predTrain <- predict(model1, train, type = "class")
table(predTrain, train$HTWins)

#Output predict csv file for Kaggle upload
predValid <- predict(model1, test, type = "class")
samplecsv = data.frame(id = test.full$id, HTWins = predValid)
write.csv(samplecsv, file = "sample.csv", row.names = F)
```

```{r}
#Ensemble Method
library(mlbench)
library(caret)
library(caretEnsemble)
library("SuperLearner")
library(ranger)
 
#Change response variable type
#Load variable
y <- as.numeric(train$HTWins)-1
ytest <- as.numeric(test$HTWins)-1
x <- data.frame(train[,-1])
xtest <- data.frame(test[,-1])

listWrappers()

set.seed(150)
single.model <- SuperLearner(y,
                             x,
                             family=binomial(),
                             SL.library=list("SL.ranger"))

single.model

set.seed(150)

# Fit the ensemble model
model <- SuperLearner(y,
                      x,
                      family=binomial(),
                      SL.library=list("SL.ranger",
                                     "SL.ksvm",
                                     "SL.ipredbagg",
                                     "SL.bayesglm"))

# Return the model
model

# Set the seed
set.seed(150)

# Get V-fold cross-validated risk estimate
cv.model <- CV.SuperLearner(y,
                            x,
                            V=5,
                            SL.library=list("SL.ranger",
                                            "SL.ksvm",
                                            "SL.ipredbagg",
                                            "SL.bayesglm"))

# Print out the summary statistics
summary(cv.model)

plot(cv.model)

predictions <- predict.SuperLearner(model, newdata=xtest)
head(predictions$pred)
head(predictions$library.predict)
conv.preds <- as.factor(ifelse(predictions$pred>=0.5,"Yes", "No"))

#Output predict csv file for Kaggle upload
samplecsv = data.frame(id = test.full$id, HTWins = conv.preds)
write.csv(samplecsv, file = "sample.csv", row.names = F)
```

Caret - Cross Validation
Creating useful function for modeling
---------------------
```{r modeling / accuracy / trainControl function}
#creating function for Caret modeling

model <- function(method, training, control,grid,...){

  if(is.null(grid)){
    model.fit <- train(Survived~.,
                     data = training,
                     method = method,
                     trControl = control,
                     ...)
    return(model.fit)
  }

  else{
    model.fit <- train(Survived~.,
                     data = training,
                     method = method,
                     trControl = control,
                     tuneGrid = grid,
                     ...)
    return(model.fit)
  }
}

#accuracy of model
acc <- function(pred, act, data){
  return(sum(diag(table(pred, act)))/nrow(data))
}

#10 folds cv
control <- trainControl(method = "cv", number = 10)
```

```{r GBM}
boost.model <- train(HTWins~.,
                   data = train,
                   method = "gbm",
                   verbose = FALSE,
                   trControl = control,
                   tuneGrid = NULL)

boost.model
summary(boost.model$finalModel)
```

```{r}
library(xgboost)
library(tidyverse)
train_y = train[,'HTWins']
train_y <- as.numeric(as.factor(train_y)) - 1
train_x = train[, names(train) !='HTWins'] %>% select_if(is.numeric)

test_y = test[,'HTWins']
test_y <- as.numeric(as.factor(test_y)) - 1
test_x = test[, names(test) !='HTWins'] %>% select_if(is.numeric)

dtrain = xgb.DMatrix(data =  as.matrix(train_x), label = train_y )
dtest = xgb.DMatrix(data =  as.matrix(test_x), label = test_y)

# these are the datasets the rmse is evaluated for at each iteration
watchlist = list(train=dtrain, test=dtest)


# try 1 - off a set of paramaters I know work pretty well for most stuff

bst = xgb.train(data = dtrain, 
                max.depth = 8, 
                eta = 0.3, 
                nthread = 2, 
                nround = 1000, 
                watchlist = watchlist, 
                objective = "binary:logistic", 
                early_stopping_rounds = 50,
                print_every_n = 500)

bst_slow = xgb.train(data = dtrain, 
                        max.depth=5, 
                        eta = 0.01, 
                        nthread = 2, 
                        nround = 10000, 
                        watchlist = watchlist, 
                        objective = "reg:linear", 
                        early_stopping_rounds = 50,
                        print_every_n = 500)
```

SVM - kernel radial
-------------------

```{r SVM}

svm.radial <- model("svmRadial", train, control, grid = NULL, tuneLength = 10)
svm.radial 

max(svm.radial$results$Accuracy)
#83.16%

varImp(svm.radial)
#name and Age

#Grid Search for tuning parameter
svm.grid <- expand.grid(sigma = seq(0.01,0.1, by=0.01),
                        C = seq(0.01,2.01,by=0.25))

svm.radial <- model("svmRadial", training %>% subset(select = -c(name, Age)), 
                    control, 
                    grid = svm.grid)

svm.radial$bestTune
max(svm.radial$results$Accuracy)
#0.8160

#on training
svm.radial.pred <- predict(svm.radial, training)

confusionMatrix(svm.radial.pred, training$Survived)
#0.8395

acc(svm.radial.pred, training$Survived, training) - max(svm.radial$results$Accuracy)
#0.0235
```


```{r}
library(keras)
library(tensorflow)
library(readr)

train.m<-data.matrix(train)
test.m<-data.matrix(test)

#Data partition
x_training<-train[, names(train) !='HTWins'] %>% select_if(is.numeric)
x_testing<-test[, names(train) !='HTWins'] %>% select_if(is.numeric)
y_training<-train[,'HTWins']
y_testing<-test[,'HTWins']

y_training<-to_categorical(y_training)
y_testing<-to_categorical(y_testing)


htwin_pred_fn <- function(data) {
    input_fn(data, 
             features = c("HTWins","VT","HT","VTleague","HTleague","date","VTcumRest","HTcumRest","VT.TA.fgm","VT.TA.blk","VT.OTS.ast","VT.OTS.to","VT.OTA.tpm","VT.OTA.oreb",
                          "VT.OTA.dreb","VT.OTA.stl","VT.OTA.pf","VT.S1.pts","VT.S1.min","VT.S1.stl","VT.S1.ast","VT.S2.plmin","VT.S2.pts","VT.S2.min","VT.S2.stl","VT.S2.ast",
                          "VT.S3.pts","VT.S3.min","VT.S3.stl","VT.S3.ast","VT.S4.pts","VT.S4.min","VT.S4.stl","VT.S4.ast","VT.S5.pts","VT.S5.min","VT.S5.stl","VT.S5.ast",
                          "VT.OS1.dreb","VT.OS1.to","VT.OS1.fgm","VT.OS1.oreb","VT.OS2.dreb","VT.OS2.to","VT.OS2.fgm","VT.OS2.oreb","VT.OS3.dreb","VT.OS3.to","VT.OS3.fgm",
                          "VT.OS3.oreb","VT.OS4.plmin","VT.OS4.dreb","VT.OS4.to","VT.OS4.fgm","VT.OS4.oreb","VT.OS5.plmin","VT.OS5.dreb","VT.OS5.to","VT.OS5.fgm","VT.OS5.oreb",
                          "VT.pmxU","VT.pmxW","HT.TS.fgm","HT.TS.fga","HT.TS.tpm","HT.TS.tp","HT.TS.fta","HT.TS.oreb","HT.TS.dreb","HT.TS.ast","HT.TS.stl","HT.TS.blk","HT.TS.to",
                          "HT.TS.pf","HT.TS.pts","HT.TA.fgm","HT.TA.fga","HT.TA.tpm","HT.TA.tpa","HT.TA.fta","HT.TA.oreb","HT.TA.dreb","HT.TA.ast","HT.TA.stl","HT.TA.blk",
                          "HT.TA.to","HT.TA.pf","HT.TA.pts","HT.OTS.fgm","HT.OTS.fga","HT.OTS.tpm","HT.OTS.tpa","HT.OTS.fta","HT.OTS.oreb","HT.OTS.dreb","HT.OTS.ast","HT.OTS.stl",
                          "HT.OTS.blk","HT.OTS.to","HT.OTS.pf","HT.OTS.pts","HT.OTA.fgm","HT.OTA.fga","HT.OTA.tpm","HT.OTA.tpa","HT.OTA.fta","HT.OTA.oreb","HT.OTA.dreb",
                          "HT.OTA.ast","HT.OTA.stl","HT.OTA.blk","HT.OTA.to","HT.OTA.pf","HT.OTA.pts","HT.S1.plmin","HT.S1.pts","HT.S1.min","HT.S1.stl","HT.S1.ast","HT.S2.plmin",
                          "HT.S2.pts","HT.S2.min","HT.S2.stl","HT.S2.ast","HT.S3.plmin","HT.S3.pts","HT.S3.min","HT.S3.stl","HT.S3.ast","HT.S4.plmin","HT.S4.pts","HT.S4.min",
                          "HT.S4.stl","HT.S4.ast","HT.S5.plmin","HT.S5.pts","HT.S5.min","HT.S5.stl","HT.S5.ast","HT.OS1.plmin","HT.OS1.dreb","HT.OS1.to","HT.OS1.fgm",
                          "HT.OS1.oreb","HT.OS2.plmin","HT.OS2.dreb","HT.OS2.to","HT.OS2.fgm","HT.OS2.oreb","HT.OS3.plmin","HT.OS3.dreb","HT.OS3.to","HT.OS3.fgm","HT.OS3.oreb",
                          "HT.OS4.plmin","HT.OS4.dreb","HT.OS4.to","HT.OS4.fgm","HT.OS4.oreb","HT.OS5.plmin","HT.OS5.dreb","HT.OS5.to","HT.OS5.fgm","HT.OS5.oreb","HT.pmxU",
                          "HT.pmxW","VT.S.plmin.sum","HT.S.plmin.sum","HT.Team.plmin.zscore"), 
             response = "HTWins")
}


dnn_classifier <- function(hidden_units,
                           feature_columns,
                           model_dir = NULL,
                           n_classes = 2L,
                           weight_column = NULL,
                           label_vocabulary = NULL,
                           optimizer = "Adagrad",
                           activation_fn = "relu",
                           dropout = NULL,
                           input_layer_partitioner = NULL,
                           config = NULL)
{
  args <- as.list(environment(), all = TRUE)
  
  estimator <- py_suppress_warnings(
    tf$estimator$DNNClassifier(
      hidden_units = cast_integer_list(hidden_units),
      feature_columns = ensure_nullable_list(feature_columns),
      model_dir = resolve_model_dir(model_dir),
      n_classes = cast_scalar_integer(n_classes),
      weight_column = cast_nullable_string(weight_column),
      label_vocabulary = label_vocabulary,
      optimizer = optimizer,
      activation_fn = resolve_activation_fn(activation_fn),
      dropout = cast_nullable_scalar_double(dropout),
      input_layer_partitioner = input_layer_partitioner,
      config = config
    )
  )

  new_tf_classifier(estimator, args = args, 
                    subclass = "tf_estimator_classifier_dnn_classifier")
}

classifier <- dnn_classifier(
  feature_columns = feature_cols, 
  hidden_units = c(80, 40, 30), 
  n_classes = 2, 
  label_vocabulary = c("N", "Y"))

#Train tensorflow by my column selection
train(classifier, 
      input_fn = htwin_pred_fn(train))

#Predict test data by using tensorflow
predictions_test <- predict(
  classifier, 
  input_fn = htwin_pred_fn(test))

#evaluation_test <- evaluate(
#  classifier, 
#  input_fn = donor_pred_fn(donor_data_test))
```
